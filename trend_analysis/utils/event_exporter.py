import csv
import re

def export_trend_start_events(log_entries, output_csv="trend_analysis/confirmed_trend_starts.csv"):
    """
    Parses log entries to extract Confirmed Uptrend Starts (CUS) and Confirmed Downtrend Starts (CDS) 
    and exports them to a CSV file. It ensures that only unique events are exported,
    and sorts them chronologically by bar index.

    Args:
        log_entries (list[str]): A list of log strings generated by process_trend_logic.
        output_csv (str): The file path for the output CSV file.
    """
    rows = []
    # Regex to match trend start lines from the log entries
    cds_re = re.compile(r"Confirmed Downtrend Start from Bar (\d+) \(([^)]+)\)")
    cus_re = re.compile(r"Confirmed Uptrend Start from Bar (\d+) \(([^)]+)\)")
    
    processed_entries = set() # To store unique (trend_start_type, bar_index, date) tuples to avoid duplicates

    for entry_idx, entry in enumerate(log_entries):
        # Search for Confirmed Downtrend Starts (CDS)
        m_cds = cds_re.search(entry)
        if m_cds:
            bar_idx = int(m_cds.group(1))
            date_str = m_cds.group(2)
            event_key = ('downtrend', bar_idx, date_str) # Create a unique key for this event
            if event_key not in processed_entries: # Add to rows if it's a new, unique event
                rows.append({
                    'trend_start_type': 'downtrend',
                    'bar_index': bar_idx, 
                    'date': date_str
                })
                processed_entries.add(event_key)
        
        # Search for Confirmed Uptrend Starts (CUS)
        m_cus = cus_re.search(entry)
        if m_cus:
            bar_idx = int(m_cus.group(1))
            date_str = m_cus.group(2)
            event_key = ('uptrend', bar_idx, date_str) # Create a unique key for this event
            if event_key not in processed_entries: # Add to rows if it's a new, unique event
                rows.append({
                    'trend_start_type': 'uptrend',
                    'bar_index': bar_idx, 
                    'date': date_str
                })
                processed_entries.add(event_key)

    # Sort rows by bar_index first, then by trend_start_type if bar_index is the same.
    # This ensures consistent ordering.
    rows.sort(key=lambda x: (x['bar_index'], x['trend_start_type']))
    
    # Write the de-duplicated and sorted trend starts to the CSV file.
    with open(output_csv, 'w', newline='') as f:
        writer = csv.DictWriter(f, fieldnames=['trend_start_type', 'bar_index', 'date'])
        writer.writeheader() # Write the header row
        writer.writerows(rows) # Write all trend start data
    print(f"Exported {len(rows)} confirmed trend starts to {output_csv}") 